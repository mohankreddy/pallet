#summary One-sentence summary of this page.

= Introduction =
This tutorial is in the continuation of Data_Import_Tutorial 1,2,3,4. This is the last 
tutorial which completes the Data Import Section of the Mallet.
 * Feature Count Pipe
 * Feature Value String 2 Feature Vector
 * Feature Vector Sequence 2 Feature Vectors
 * Filter Empty Feature Vector
 * Instance List Trim Features By Count
 * Noop
 * Pipe
 * PrintInput
 * Print Token Sequence Features
 * Save Data In Source
 * Selective SGML 2 Token Sequence
 * Simple Tagger Sentence 2 String Tokenization
 * Token 2 Feature Vector
 * Token Sequence 2 Token Instances
 * Token Sequence Parse Feature String
 * Augmentable Feature Vector Add Conjunction



= Feature Count Pipe =
This pipe is used to prune the features which have low count.It is used in order to save the memory which could have been occupied by low count features.This class supports a simpler method that makes two passes over the data : one to collect statistics and create an augumented "stop list",and secondly to actually create instances.

==Implementation==

 * 1) FeatureCountPipe(): This is a simple constructor with no parameters which creates the instance of FeatureCountPipe.

 * 2)FeatureCountPipe(Alphabet datalphabet,Alphabet targetAlphabet): User can supply data alphabet and target alphabet explicity .

==Methods==

 * 1)void addPrunedWordsToStoplist(SimpleTokenizer tokenizer, int minimumCount): Add all pruned words to the internal stoplist of a SimpleTokenizer.

 * 2)Alphabet getPrunedAlphabet(int minimumcount): Return a new Alphabet that contains only features at or above the specified limit

 * 3)void writeCommonWords(java.io.File commonfile,int totalwords): List the most common words ,for addition to a stop file.

 * 4)void writePrunedWords(java.io.File prunedfile,int minimumcount): Write a list of features that do not occur at or above the specified cutoff to the pruned file,one per file.

 * 5)Instance pipe(Instance instance): Method used to process the data.

==Sample Code==

{{{
import cc.mallet.pipe.*;
import cc.mallet.types.*;
import java.io.*;

public class ImportExample200 {
	static Pipe pipe=null;
	
	public static void main(String args[])
	{
         SimpleTokenizer st=new SimpleTokenizer(1);
		
   String trainingdata="on the plains of  africa the lions123  roar the";
      Instance i=new Instance(trainingdata,"africa","Instance-1",null);
	Input2CharSequence i2cs=new Input2CharSequence();
	Instance i1=i2cs.pipe(i);
				
  SGML2TokenSequence cs2ts=new SGML2TokenSequence();
		 Instance i2=cs2ts.pipe(i1);
			 
  TokenSequence2FeatureSequence ts2fs=new TokenSequence2FeatureSequence();
		 Instance i3=ts2fs.pipe(i2);
				 
FeatureCountPipe fcp=new FeatureCountPipe(i3.getDataAlphabet(),i3.getTargetAlphabet());->1
		Instance i6=fcp.pipe(i3);--->2
		File f=new File("f200.txt");--->3
		try
		{
		fcp.writePrunedWords(f, 2);---->4
		}
		catch(Exception e)
		{
			System.out.println(e);
		}
		}
                }
}}}

 * 1) An instance of Feature Count Pipe is created with Data Alphabet and Target Alphabet of the previous pipe(TokenSequence2FeatureSequence in this case).
 * 2)An instance (i6) is generated which contains the data processed by FeatureCountPipe.
 * 3)A file is created which contains the pruned words.
 * 4)writePrunedWords is called with value 2. It means the words which doesn't occur more than 2 times will be pruned.

==Output==
1)The file f200.txt will contains 
on
of
africa
lions
roar

These all words doesn't occur more than two times in the raw data so will be pruned from feature set.