#Our task list from which we coordinate with one another and generate release notes.

= Reduce Complexity =
Any task listed here should take 1 hour to no more than 2 weeks work.  If a task listed will take more than 2 weeks work then it should be broken into sub-tasks that take less time.

= Tasks =
(%) - means the task needs to be broken down into several sub-tasks
== Not started (In order of priority) ==

 
 * The documentation of the following pipes have not started(%) 
   * Add Classifier Token Predictions
   * Add Classifier Token Predictions . Token Classifiers
   * Augmentable Feature Vector Add Conjunctions
   * Classification 2 Confidence Predicting Feature Vector
   * Directory 2 File Iterator
   * Feature Count Pipe
   * Feature Value String 2 Feature Vector
   * Feature Vector Sequence 2 Feature Vectors
   * Filter Empty Feature Vectors
   * Instance List Trim Features By Count
   * Noop
   * Pipe
   * Print Input
   * Print Token Sequence Features
   * Save Data In Source
   * Selective SGML 2 Token Sequence
   * Simple Tagger Sentence 2 String Tokenization
   * Token 2 Feature Vector
   * Token Sequence 2 Token Instances
   * Token Sequence Parse Feature String 
 * The unit testing of all the pipes.(%)
 * Sample Application using Data Import functionality.  
 * Data Classification:
   * Decision Trees.
     * Code Review and planned extension to support pruning.
   * C4.5 Decision Trees.
   * Balanced Winnow.
   * AdaBoost?.
   * Bootstrap Aggregating (bagging)
   * Machine Learning Ensemble.
   * Rank Maximum Entropy
   * Winnow
   * Confidence Predicting.
   * Maximum Entropy models with Generalized Expectation Criteria.
  * Data classification unit tests
  * Real Application to show the Data Import and Classification functionality.

== Currently being worked on ==
  * Currently working on the following pipes.
   * Token Sequence Remove Non Alpha
   * Token Sequence NGrams
   * SGML2 Token Sequence
   * Target 2 Feature Sequence
   * Target 2 Label Sequence
   * Token Sequence 2 Feature Vector Sequence
   * Token Sequence Feature Parse Feature String
   * Token Sequence Match Data And Target
   * Token Sequence 2FeatureSequenceWithBigrams
   * Target Remeber Last Label
   * Source Location 2 Token Sequence 
  
  * Maximum Entropy 
    * Code Review - Currently have paused this work and have moved onto Decision Tree
    * Documentation and Tutorials

  * Decision Trees
     * Documentation and Tutorials.

== Completed ==
  * The following task has been completed on the pipes(mentioned below)
    * Understanding the Algorithms
    * Documenting them
    * Small sample source code for each pipe.
    * Documenting everything in the form of small tutorials
    * Source code and Documentation Reviewed
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 Filename2CharSequence]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 CharSequenceArray2TokenSequence]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 Csv2Array]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 Array2FeatureVector]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 Csv2FeatureVector]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 TargetStringToFeatures]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 SimpleTaggerSentence2TokenSequence]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 SimpleTokenizer]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 Pipeutils]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 StringAddNewLineDelimiter]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 CharSequenceRemoveUUEncodedBlocks]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 StringList2FeatureSequence]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 FeatureSequenceConvolution]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_3 FeatureVectorConjunction]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import Input2CharSequence]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 CharSequenceReplace] 
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 CharSequenceRemoveHTML] 
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import CharSequence2TokenSequence]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import TokenSequenceRemoveStopwords]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 MakeAmpersandXMLFriendly]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import TokenSequence2Feature Sequence]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import Target2Label]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 FeatureSequence2AugmentableFeatureVector]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 AugmentableFeatureVectorLogScale]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 CharSequence2charngrams]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 CharSequenceLowecase]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 CharSubsequence]
     * [http://code.google.com/p/pallet/wiki/Data_Import_Tutorial_2 LineGroupString2TokenSequence]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import CharSequence2TokenSequence]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import TokenSequenceLowercase]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import TokenSequenceRemoveStopwords]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import Target2Label]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import FeatureSequence2FeatureVector]
     * [http://code.google.com/p/pallet/wiki/Tutorial_Data_Import PrintInputAndTarget] 

  * Naive Bayes Algorithm
    * Understanding the algorithm
    * Reviewing Mallet code to understand the implementation.
    * Documentation of the mallet implementation of the algorithm and its tutorials.
  * Maximum Entropy
    * Understanding the algorithm.